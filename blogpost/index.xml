<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Testing | Behavioral Data Science</title><link>https://www.behavioral-ds.science/blogpost/</link><atom:link href="https://www.behavioral-ds.science/blogpost/index.xml" rel="self" type="application/rss+xml"/><description>Testing</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>2023</copyright><lastBuildDate>Mon, 19 Sep 2022 00:00:00 +0000</lastBuildDate><image><url>https://www.behavioral-ds.science/img/logo.png</url><title>Testing</title><link>https://www.behavioral-ds.science/blogpost/</link></image><item><title>Acquaintances beat close friends for job connections, huge LinkedIn study shows</title><link>https://www.behavioral-ds.science/blogpost/linkedin_experiment/</link><pubDate>Mon, 19 Sep 2022 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/blogpost/linkedin_experiment/</guid><description>&lt;h2 id="radio-adelaide-breakfast-interview">Radio Adelaide Breakfast interview:&lt;/h2>
&lt;p>&lt;audio
controls
src="RadioAdelaideBreakfast.mp3">
Your browser does not support the
&lt;code>audio&lt;/code> element.
&lt;/audio>&lt;/p>
&lt;p>Say you are looking for a new job. You head to LinkedIn to spruce up your profile and look around your social network.&lt;/p>
&lt;p>But who should you reach out to for an introduction to a potential new employer? A &lt;a href="https://www.science.org/doi/10.1126/science.abl4476">new study&lt;/a> of more than 20 million people, published in Science, shows that your close friends (on LinkedIn) are not your best bet: instead you should look to acquaintances you don't know well enough to share a personal connection with.&lt;/p>
&lt;h2 id="the-strength-of-weak-ties">The strength of weak ties&lt;/h2>
&lt;p>In 1973, the American sociologist &lt;a href="https://sociology.stanford.edu/people/mark-granovetter">Mark Granovetter&lt;/a> coined the phrase &amp;ldquo;&lt;a href="https://doi.org/10.1086%2F225469">the strength of weak ties&lt;/a>&amp;rdquo; in the context of social networks. He argued that the stronger the ties between two individuals, the more their friendship networks will overlap.&lt;/p>
&lt;p>Simply put, you are most likely to know all the friends of a close friend, but few of the friends of an acquaintance.&lt;/p>
&lt;p>So if you are searching for a job, you probably already know everything your immediate neighbourhood has to offer. Intuitively, it is the weak ties – your acquaintances – that offer the most opportunities for new discoveries.&lt;/p>
&lt;h2 id="weak-ties-and-jobs">Weak ties and jobs&lt;/h2>
&lt;p>Granovetter's theory feels right, but is it? A team of researchers from LinkedIn, Harvard Business School, Stanford and MIT set out to gather some empirical evidence on how weak ties affect job mobility.&lt;/p>
&lt;p>Their research piggy-backed on the efforts of engineers at LinkedIn to test and improve the platform's &amp;ldquo;People You May Know&amp;rdquo; recommendation algorithm. LinkedIn regularly updates this algorithm, which recommends new people to add to your network.&lt;/p>
&lt;p>One of these updates tested the effects of encouraging the formation of strong ties (recommending adding your close friends) versus weak ties (recommending acquaintances and friends of friends). The researchers then followed the users that participated in this &amp;ldquo;A/B testing&amp;rdquo; to see if the difference impacted their employment outcomes.&lt;/p>
&lt;p>More than 20 million LinkedIn users worldwide were randomly assigned to well-defined treatment groups. Users in each group were shown slightly different new contact recommendations, which led users in some groups to form more strong ties and users in other groups to form more weak ties.&lt;/p>
&lt;p>Next, the team measured how many jobs users in each group applied for, and how many &amp;ldquo;job transmissions&amp;rdquo; occurred. Job transmissions are of particular interest, as they are defined as getting a job in the same company as the new contact. A job transmission suggests the new contact helped land the job.&lt;/p>
&lt;h2 id="moderately-weak-ties-are-best">Moderately weak ties are best&lt;/h2>
&lt;p>The study uses causal analysis to go beyond simple correlations and connect link formation with employment. There are three important findings.&lt;/p>
&lt;p>First, the recommender engine significantly shapes link formation. Users who were recommended more weak links formed significantly more weak links, and users who were recommended more strong links formed more strong links.&lt;/p>
&lt;p>Second, the experiment provides causal evidence that moderately weak ties are more than twice as effective as strong ties in helping a job-seeker join a new employer. What's a &amp;ldquo;moderately&amp;rdquo; weak tie? The study found job transmission is most likely from acquaintances with whom you share about 10 mutual friends and rarely interact.&lt;/p>
&lt;p>Third, the strength of weak ties varied by industry. Whereas weak ties increased job mobility in more digital industries, strong ties increased job mobility in less digital industries.&lt;/p>
&lt;h2 id="better-recommendations">Better recommendations&lt;/h2>
&lt;p>This LinkedIn study is first to causally prove Granovetter's theory in the employment market. The causal analysis is key here, as large-scale studies of correlations between strength of ties and job transmission have shown strong ties are more beneficial, in what was considered until now a paradox.&lt;/p>
&lt;p>This study resolves the paradox and again proves the limitations of correlation studies, which do a poor job at disentangling confounding factors and sometimes lead to the wrong conclusions.&lt;/p>
&lt;p>From a practical point of view, the study outlines the best parameters for suggesting new links. It revealed that the connections most helpful in landing a job are your acquaintances, people you meet in professional settings, or friends of friends, rather than your closest friends – people with whom you share about 10 mutual contacts and with whom one is less likely to interact regularly.&lt;/p>
&lt;p>These can be translated into algorithmic recommendations, which can make the recommendation engines of professional networks such as LinkedIn even more proficient at helping job-seekers land jobs.&lt;/p>
&lt;h2 id="the-power-of-black-boxes">The power of black boxes&lt;/h2>
&lt;p>The public is often wary when large social media companies perform experiments on their users (see &lt;a href="https://www.bbc.com/news/technology-28051930">Facebook's infamous emotion experiment of 2014&lt;/a>).&lt;/p>
&lt;p>So, could LinkedIn's experiment have harmed its users? In theory, the users in the &amp;ldquo;strong link&amp;rdquo; treatment group might have missed the weak links that could have brought their next job.&lt;/p>
&lt;p>However, all groups had some degree of job mobility – some just a bit more than others. Moreover, since the researchers were observing an engineering experiment, the study itself seems to raise few ethical concerns.&lt;/p>
&lt;p>Nonetheless, it is a reminder to ask how much our most intimate professional decisions – such as selecting a new career or workplace – are determined by black-box artificial intelligence algorithms whose workings we cannot see.&lt;/p></description></item><item><title>Doing research online (by SAGE Research Methods): A Mixed-Method to Explain How Extreme Opinions Infiltrate Online Discussions</title><link>https://www.behavioral-ds.science/blogpost/sage-research-methods-online-problematic-content/</link><pubDate>Wed, 27 Jul 2022 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/blogpost/sage-research-methods-online-problematic-content/</guid><description>&lt;iframe scrolling="no" webkitAllowFullScreen="true" mozallowfullscreen="true" allowFullScreen="true" width="640" height="360" src="https://methods.sagepub.com/video/embed/srmpromo/21fyoz/mapping-online-problematic-content-mixing-approaches">Your browser does not support iFrames.&lt;/iframe>
&lt;p>&lt;a href="https://www.behavioral-ds.science/authors/ma-rizoiu/">Andrei&lt;/a> was interviewed by SAGE Research Methods for the &lt;a href="https://uk.sagepub.com/en-gb/eur/sage-research-methods-doing-research-online">Doing Online Research&lt;/a> case study collection.
He discusses a case study using qualitative approaches and machine learning to map online problematic content, including blending digital ethnography and advanced machine learning, data collection, dataset augmentation, results, lessons learned, and recommendations.&lt;/p>
&lt;p>There is a strong focus on the interdisciplinarity of the work &amp;ndash; a collaborations with digital communication scientists &lt;a href="https://profiles.uts.edu.au/Amelia.Johns">Amelia Johns&lt;/a> and &lt;a href="https://profiles.uts.edu.au/Francesco.Bailo">Francesco Bailo&lt;/a>, literary scientist &lt;a href="https://profiles.uts.edu.au/Emily.Booth">Emily Booth&lt;/a>, and computer scientists &lt;a href="https://www.behavioral-ds.science/authors/quyu-kong/">Quyu Kong&lt;/a> and &lt;a href="https://www.behavioral-ds.science/authors/ma-rizoiu/">Marian-Andrei Rizoiu&lt;/a>.&lt;/p>
&lt;p>The interview is based on our &lt;a href="https://arxiv.org/pdf/2109.00302.pdf">recent paper&lt;/a> published in &lt;a href="https://www.icwsm.org/2022/index.html/">ICWSM 2022&lt;/a>, where we propose a complete solution to accelerate the qualitative analysis of problematic online speech — with a specific focus on opinions emerging from online communities — by leveraging machine learning algorithms.&lt;/p>
&lt;p>&lt;strong>Paper citation:&lt;/strong>&lt;/p>
&lt;pre>&lt;code>Quyu Kong, Emily Booth, Francesco Bailo, Amelia Johns, and Marian-Andrei
Rizoiu. Slipping to the Extreme: A Mixed Method to Explain How Extreme
Opinions Infiltrate Online Discussions. In AAAI International Conference
on Web and Social Media (Vol. 16, pp. 524–535), 2022.
&lt;/code>&lt;/pre>
&lt;p>(see full paper here: &lt;a href="https://arxiv.org/pdf/2109.00302.pdf">https://arxiv.org/pdf/2109.00302.pdf&lt;/a>, and a full description of the research in &lt;a href="https://www.behavioral-ds.science/theme2_content/icwsm2022/">this blogpost&lt;/a>)&lt;/p>
&lt;p>&lt;strong>Acknowledgements:&lt;/strong>&lt;br>
This research was partially funded by the University of Technology of Sydney through a cross-faculty grant, Facebook Research under the Content Policy Research Initiative, and the Commonwealth of Australia (represented by the Defence Science and Technology Group) through a Defence Science Partnerships Agreement.&lt;/p></description></item><item><title>Slipping to the Extreme: A Mixed-Method to Explain How Extreme Opinions Infiltrate Online Discussions</title><link>https://www.behavioral-ds.science/blogpost/icwsm2022/</link><pubDate>Mon, 13 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/blogpost/icwsm2022/</guid><description>&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/HwFq3ywanp4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;p>In our &lt;a href="https://arxiv.org/pdf/2109.00302.pdf">recent paper&lt;/a> accepted at &lt;a href="https://www.icwsm.org/2022/index.html/">ICWSM 2022&lt;/a>, we propose a complete solution to accelerate the qualitative analysis of problematic online speech — with a specific focus on opinions emerging from online communities — by leveraging machine learning algorithms.&lt;/p>
&lt;p>&lt;strong>Paper citation:&lt;/strong>&lt;/p>
&lt;pre>&lt;code>Quyu Kong, Emily Booth, Francesco Bailo, Amelia Johns, and Marian-Andrei
Rizoiu. Slipping to the Extreme: A Mixed-Method to Explain How Extreme
Opinions Infiltrate Online Discussions. In: Proceedings of the 16TH AAAI
International Conference on Web and Social Media, 2022.
&lt;/code>&lt;/pre>
&lt;p>(see full paper here: &lt;a href="https://arxiv.org/pdf/2109.00302.pdf">https://arxiv.org/pdf/2109.00302.pdf&lt;/a>)&lt;/p>
&lt;h3 id="problematic-speech-a-modern-plague">Problematic Speech: A Modern Plague&lt;/h3>
&lt;p>Problematic speech is online interactions, speech, and artifacts that are inaccurate, misleading, inappropriately attributed, or altogether fabricated [1].
In 2020, the COVID-19 pandemic alerted the world to complex issues that arise from social media platforms circulating user-generated misinformation, hate speech, and conspiracy theories [2].
There are several primary types of quantitative methods for addressing problematic information, including large-scale monitoring of social media datasets [3], understanding platforms, users, and networks contributing to the &amp;ldquo;infodemic&amp;rdquo; [4], and predicting future pathways of information spreading [5].
These studies provide valuable insights into understanding how problematic information spreads and detecting which sources are reshared frequently and by which accounts.
However, these approaches often have less to say about why certain opinions and views gain traction with vulnerable groups and online communities.&lt;/p>
&lt;p>Qualitative research methods are well placed to address this gap.
They provide rich, contextual insights into online communities&amp;rsquo; social beliefs, values, and practices, which shape how information is shared and how opinions are formed [6].
Nevertheless, a common criticism of qualitative research is that the in-depth knowledge comes at the expense of generating insights of limited representativeness and weak robustness of the findings.
Therefore, there is a gap between the depth of insight gained from ethnographic and qualitative approaches and the breadth of knowledge gained from computational methods from data science.&lt;/p>
&lt;p>Our work fills this gap by proposing a mixed-method approach that combines qualitative insights, large-scale data collection, and human-in-the-loop machine learning approaches.
We apply our method to map in-depth and in-breadth the problematic information around four topics:
&lt;em>2019-20 Australian bushfire season&lt;/em>,
&lt;em>Climate change&lt;/em>,
&lt;em>COVID-19&lt;/em>, and
&lt;em>Vaccination&lt;/em>
on three social media platforms (Facebook, Twitter, and YouTube).&lt;/p>
&lt;h2 id="our-solution-mixing-digital-ethnography-with-advanced-machine-learning">Our Solution: Mixing Digital Ethnography with Advanced Machine Learning&lt;/h2>
&lt;p>&lt;img src="fig1.png" alt="The pipeline of machine learning accelerated qualitative research where the human-in-the-loop machine learning algorithms are employed for dataset augmentation.">&lt;/p>
&lt;p>We present a complete solution that bridges and facilitates qualitative and quantitative analysis to study problematic online speech.
The pipeline consists of three components which are detailed in this section.&lt;/p>
&lt;h3 id="deep-qualitative-study">Deep qualitative study&lt;/h3>
&lt;p>The first component is the qualitative study.
We build a platform based on an open-source tool, &lt;a href="https://wikiba.se/">&lt;em>Wikibase&lt;/em>&lt;/a>, where we conduct qualitative and quantitative analysis.
Through the quantitative study, we build an ontology of problematic online speech.
We label a large number of social media postings using their topics.
Simultaneously, we construct a vocabulary of 71 opinions that we also use to label postings.
Some example opinions include:&lt;/p>
&lt;ul>
&lt;li>Climate change crisis isn't real&lt;/li>
&lt;li>United Nations is corrupt&lt;/li>
&lt;li>Climate change is a UN hoax&lt;/li>
&lt;li>United Nations wants to be the global ruling government&lt;/li>
&lt;li>Vaccines cause Autism&lt;/li>
&lt;li>The World Health Organisation is corrupt&lt;/li>
&lt;/ul>
&lt;p>These opinions contain mistrust in the government and supra-national structures (e.g., UN, WHO) and typical misinformation about vaccines.&lt;/p>
&lt;h3 id="unlabeled-data-collection">Unlabeled data collection&lt;/h3>
&lt;p>Qualitative approaches analyze emerging content and construct the vocabulary simultaneously when labeling the data.
However, they lack representativeness as they tend to be overly concentrated on narrow areas of the narrative landscape.
For this reason, the second step in our methodology involves collecting data at scale.
We collect large-scale raw data using the uncovered vocabulary from the deep qualitative study.
We construct keywords (shown in the table) for each topic to crawl social media data from three platforms.
We obtain a total of &lt;strong>13,321,813&lt;/strong> postings — &lt;strong>11,437,009&lt;/strong> Facebook postings, &lt;strong>1,793,927&lt;/strong> tweets and &lt;strong>90,877&lt;/strong> YouTube comments.&lt;/p>
&lt;p>&lt;img src="table.png" alt="keywords">&lt;/p>
&lt;h3 id="dataset-augmentation">Dataset augmentation&lt;/h3>
&lt;p>The next step is to annotate all the postings in our dataset automatically.
We employ machine learning algorithms to augment the data labeling process with a human-in-the-loop setting.&lt;/p>
&lt;p>By adopting the state-of-the-art text classification algorithm, RoBERTa [7,8], we first train the classifiers to identify problematic speech on postings annotated by the qualitative researchers.
Next, we deploy three strategies to select unlabeled data.
The active learning [9] strategy selects the data for which the classifiers are most uncertain.
The top-confidence strategy selects data that classifiers are most certain about.
The third strategy — the random strategy — randomly samples from unlabeled data.
The qualitative researchers then label the sampled data, introduce the newly labeled data in the ontology, and repeat the procedure iteratively until the predictive performance converges.&lt;/p>
&lt;h2 id="humanintheloop-performance">Human-in-the-loop Performance&lt;/h2>
&lt;p>We discuss here the convergence of prediction performance over labeling iterations.&lt;/p>
&lt;p>The following plot depicts the prediction performance on the test set macro-averaged over topics (accuracy in the left panel and F1 score on the right panel) over iterations.
The solid lines show the performance indicators, together with the cross-validation generalization error.&lt;/p>
&lt;p>The cross-validation performance is stable across iterations.
This is expected as the classifiers learn from the same data on which the generalization is estimated — i.e., the classifiers are representative of the data they were trained on.
However, the difference between the test set performance and cross-validation performance is indicative of the representativity over the entire dataset.
The cross-validation accuracy is consistently lower than the test set accuracy because the test data is more imbalanced than labeled data.
The cross-validation F1 is more optimistic than the test set F1.
Finally, the difference between the two stabilizes for the later iterations, further suggesting the convergence.
&lt;img src="fig3.png" alt="Convergence of topic classifier performances over seven iterations.">&lt;/p>
&lt;h2 id="applying-the-qualitative-mapping">Applying the Qualitative Mapping&lt;/h2>
&lt;p>We employ the obtained augmented labeled set to analyze the dynamics of problematic opinions at scale.
We machine-label the opinions in a large set of postings spanning over a long time, allowing us to apply the qualitative-defined coding schema to a significantly larger sample of postings.
This reduces the unavoidable selection bias of the deep qualitative study.
It also offers a critical tool for analyzing co-occurring opinions, which helps identify central opinions.
It is common for postings to express multiple opinions.&lt;/p>
&lt;p>We explore central opinions by building an opinion co-occurrence network in the online conversation of the topic &lt;strong>2019-20 Australian bushfire season&lt;/strong>.
In the network, nodes are the opinions captured during the bushfire conversation, while edges are present when both opinions are detected in the same postings.
The node degree of a given opinion node represents the number of opinions that co-occurred with it.
The edges are weighted by the number of postings in which their connected node opinions co-occurred.&lt;/p>
&lt;p>The following plot presents each edge's daily proportions of weights among all edges between September 2019 and January 2020.
We show six edges (i.e., opinion pairs) to represent three types of temporal dynamics:&lt;/p>
&lt;ul>
&lt;li>A continuous and relatively strong association between prevalent opinions — &amp;ldquo;Climate change crisis isn't real&amp;rdquo; and &amp;ldquo;Climate change is a UN hoax,&amp;rdquo; which not notably is a conspiracy theory.&lt;/li>
&lt;li>Associations with declining relative frequencies — &amp;ldquo;Greta Thunberg should not have a platform or influence as a climate&amp;hellip;&amp;rdquo; and &amp;ldquo;Women and girls don't deserve a voice in the public sphere&amp;rdquo;.&lt;/li>
&lt;li>Rising associations such as &amp;ldquo;bushfires and climate change not related&amp;rdquo; and &amp;ldquo;bushfires were caused by random arsonists&amp;rdquo;; and also the conspiracy theory associations between &amp;ldquo;United Nations is corrupt&amp;rdquo; and &amp;ldquo;United Nations wants to be the global ruling government&amp;rdquo;.
&lt;img src="fig2.png" alt="Daily proportions of edge weights of six selected co-occurred opinions pairs.">&lt;/li>
&lt;/ul>
&lt;p>In the following plot, we map the co-occurrence network from posts published over 14 days in late September 2019, i.e., the period when the betweenness for conspiracy opinions is at peak.
This figure explains the ambivalent network role that conspiracy opinions can play: we first note a conspiracy opinion with relatively high degree and frequency — &amp;ldquo;Climate change is a UN hoax&amp;rdquo; —, while we also observe the presence of low degree but high betweenness conspiracy opinions at the periphery of the network — &amp;ldquo;Bushfires linked to secret elites&amp;rsquo; secret technology (chemtrails, HAARP, HSRN, geoengineering)&amp;quot;, &amp;ldquo;bushfires deliberately lit to promote a climate change agenda&amp;rdquo; and &amp;ldquo;Australia should not be a member of the United Nations&amp;rdquo;.&lt;/p>
&lt;p>&lt;img src="featured.png" alt="A visualization of the co-occurrence network in late September 2020 — node sizes and colors indicate the degrees and betweenness values">&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;p>[1] Jack, C. 2017. Lexicon of lies: Terms for problematic information. Data &amp;amp; Society.&lt;br>
[2] Posetti, J.; and Bontcheva, K. 2020. Disinfodemic: deciphering COVID-19 disinformation. Policy brief 1.&lt;br>
[3] Ram, R.; Kong, Q.; and Rizoiu, M.-A. 2021. Birdspotter: A Tool for Analyzing and Labeling Twitter Users. In WSDM. ACM.&lt;br>
[4] Smith, N.; and Graham, T. 2019. Mapping the anti-vaccination movement on Facebook. Information, Communication &amp;amp; Society.&lt;br>
[5] Molina, M. D.; Sundar, S. S.; Le, T.; and Lee, D. 2019. “Fake news” is not simply false information: a concept explication and taxonomy of online content. American behavioral scientist&lt;br>
[6] Glaeser, E. L.; and Sunstein, C. R. 2009. Extremism and social learning. Journal of Legal Analysis.&lt;br>
[7] Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, L.; and Polosukhin, I. 2017. Attention is all you need. In NeurIPS.&lt;br>
[8] Liu, Y.; Ott, M.; Goyal, N.; Du, J.; Joshi, M.; Chen, D.; Levy, O.; Lewis, M.; Zettlemoyer, L.; and Stoyanov, V. 2019. Roberta: A robustly optimized BERT pretraining approach. arXiv.&lt;br>
[9] Settles, B. 2012. Active learning. Synthesis lectures on artificial intelligence and machine learning.&lt;/p></description></item></channel></rss>